# mobllm
An inference engine for high-performance execution of LLMs on mobile devices.
